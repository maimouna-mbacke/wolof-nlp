{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wolof NLP Toolkit - Quickstart\n",
    "\n",
    "This notebook demonstrates the core functionality of the Wolof NLP toolkit.\n",
    "\n",
    "## Installation\n",
    "\n",
    "```bash\n",
    "pip install wolof-nlp\n",
    "```\n",
    "\n",
    "Or for development:\n",
    "```bash\n",
    "git clone https://github.com/maimouna-mbacke/wolof-nlp\n",
    "cd wolof-nlp\n",
    "pip install -e .\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wolof NLP loaded successfully\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../src')\n",
    "\n",
    "from wolof_nlp import (\n",
    "    WolofTokenizer,\n",
    "    tokenize,\n",
    "    morphemes,\n",
    "    normalize,\n",
    "    analyze_morphology\n",
    ")\n",
    "\n",
    "print(\"Wolof NLP loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Two Tokenization Modes\n",
    "\n",
    "The toolkit provides two tokenization modes:\n",
    "- `tokenize()`: Word-level tokenization for standard NLP pipelines\n",
    "- `morphemes()`: Morpheme-level splitting for linguistic analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input                tokenize()                morphemes()\n",
      "----------------------------------------------------------------------\n",
      "Damay dem.           ['Damay', 'dem']          ['da', 'ma', 'y', 'dem']\n",
      "Dafa baax.           ['Dafa', 'baax']          ['Dafa', 'baax']\n",
      "Dinaa lekk.          ['Dinaa', 'lekk']         ['di', 'na', 'a', 'lekk']\n"
     ]
    }
   ],
   "source": [
    "examples = [\n",
    "    (\"Damay dem.\", \"I'm going\"),\n",
    "    (\"Dafa baax.\", \"It's good\"),\n",
    "    (\"Dinaa lekk.\", \"I will eat\"),\n",
    "]\n",
    "\n",
    "print(f\"{'Input':<20} {'tokenize()':<25} {'morphemes()'}\")\n",
    "print(\"-\" * 70)\n",
    "for text, meaning in examples:\n",
    "    tok_result = tokenize(text)\n",
    "    morph_result = morphemes(text)\n",
    "    print(f\"{text:<20} {str(tok_result):<25} {morph_result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Language Detection\n",
    "\n",
    "The tokenizer detects Wolof, French, Arabic loanwords, and Senegalese place names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: Sénégal dafa neex trop billahi\n",
      "\n",
      "  Sénégal      -> WOLOF\n",
      "  dafa         -> WOLOF\n",
      "  neex         -> WOLOF\n",
      "  trop         -> FRENCH\n",
      "  billahi      -> ARABIC\n"
     ]
    }
   ],
   "source": [
    "tokenizer = WolofTokenizer(normalize=True, detect_language=True)\n",
    "\n",
    "text = \"Sénégal dafa neex trop billahi\"\n",
    "tokens = tokenizer.tokenize(text)\n",
    "\n",
    "print(f\"Input: {text}\\n\")\n",
    "for tok in tokens:\n",
    "    if tok.type.name == 'WORD':\n",
    "        print(f\"  {tok.text:<12} -> {tok.language.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Orthography Normalization\n",
    "\n",
    "Converts informal/non-standard spellings to CLAD standard orthography, without altering meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Informal             CLAD Standard        Meaning\n",
      "------------------------------------------------------------\n",
      "dieuradieuf          jërëjëf              Thank you\n",
      "serigne              seriñ                Sir/Mister\n",
      "sokhna               soxna                Madam\n",
      "thiep bi neex na     ceeb bi neex na      The rice is delicious\n"
     ]
    }
   ],
   "source": [
    "examples = [\n",
    "    (\"dieuradieuf\", \"jërëjëf\", \"Thank you\"),\n",
    "    (\"serigne\", \"seriñ\", \"Sir/Mister\"),\n",
    "    (\"sokhna\", \"soxna\", \"Madam\"),\n",
    "    (\"thiep bi neex na\", \"ceeb bi neex na\", \"The rice is delicious\"),\n",
    "]\n",
    "\n",
    "print(f\"{'Informal':<20} {'CLAD Standard':<20} {'Meaning'}\")\n",
    "print(\"-\" * 60)\n",
    "for informal, expected, meaning in examples:\n",
    "    normalized = normalize(informal)\n",
    "    print(f\"{informal:<20} {normalized:<20} {meaning}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Morphological Analysis\n",
    "\n",
    "Decomposes words into constituent morphemes with grammatical labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bindkat      -> bind:ROOT + kat:NOMINALIZATION\n",
      "             (writer (bind + kat))\n",
      "\n",
      "soppiku      -> soppi:ROOT + ku:REFLEXIVE\n",
      "             (to change oneself (soppi + ku))\n",
      "\n",
      "gisante      -> gis:ROOT + ante:RECIPROCAL\n",
      "             (to see each other (gis + ante))\n",
      "\n",
      "defaat       -> def:ROOT + aat:REPETITIVE\n",
      "             (to do again (def + aat))\n",
      "\n",
      "demul        -> dem:ROOT + ul:NEGATION\n",
      "             (didn't go (dem + ul))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "words = [\n",
    "    (\"bindkat\", \"writer (bind + kat)\"),\n",
    "    (\"soppiku\", \"to change oneself (soppi + ku)\"),\n",
    "    (\"gisante\", \"to see each other (gis + ante)\"),\n",
    "    (\"defaat\", \"to do again (def + aat)\"),\n",
    "    (\"demul\", \"didn't go (dem + ul)\"),\n",
    "]\n",
    "\n",
    "for word, meaning in words:\n",
    "    morphs = analyze_morphology(word)\n",
    "    morph_str = \" + \".join(f\"{m.text}:{m.type.name}\" for m in morphs)\n",
    "    print(f\"{word:<12} -> {morph_str}\")\n",
    "    print(f\"             ({meaning})\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Processing Real-World Text\n",
    "\n",
    "Example with typical Senegalese social media text featuring code-switching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Dafa trop neex série bi wallahi\n",
      "  Wolof:  ['Dafa', 'neex', 'bi']\n",
      "  French: ['trop', 'série']\n",
      "  Arabic: ['wallahi']\n",
      "\n",
      "Text: Masha Allah vraiment rafet\n",
      "  Wolof:  ['rafet']\n",
      "  French: ['vraiment']\n",
      "  Arabic: ['Allah']\n",
      "\n",
      "Text: Dem naa Dakar tey\n",
      "  Wolof:  ['Dem', 'na', 'a', 'Dakar', 'tey']\n",
      "  French: []\n",
      "  Arabic: []\n",
      "\n"
     ]
    }
   ],
   "source": [
    "comments = [\n",
    "    \"Dafa trop neex série bi wallahi\",\n",
    "    \"Masha Allah vraiment rafet\",\n",
    "    \"Dem naa Dakar tey\",\n",
    "]\n",
    "\n",
    "for comment in comments:\n",
    "    tokens = tokenizer.tokenize(comment)\n",
    "    words = [t for t in tokens if t.type.name == 'WORD']\n",
    "    \n",
    "    wolof = [t.text for t in words if t.language and t.language.name == 'WOLOF']\n",
    "    french = [t.text for t in words if t.language and t.language.name == 'FRENCH']\n",
    "    arabic = [t.text for t in words if t.language and t.language.name == 'ARABIC']\n",
    "    \n",
    "    print(f\"Text: {comment}\")\n",
    "    print(f\"  Wolof:  {wolof}\")\n",
    "    print(f\"  French: {french}\")\n",
    "    print(f\"  Arabic: {arabic}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "- See `02_applications.ipynb` for POS tagging, NER, sentiment analysis\n",
    "- See `03_evaluation.ipynb` for evaluation on gold standard data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
