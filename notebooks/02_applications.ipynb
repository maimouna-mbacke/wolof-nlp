{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wolof NLP - Applications\n",
    "\n",
    "This notebook demonstrates the higher-level NLP applications built on top of the core tokenizer.\n",
    "\n",
    "Available applications:\n",
    "- **POS Tagging**: Part-of-speech tagging with morphology-based rules\n",
    "- **NER**: Named entity recognition with Senegalese gazetteers\n",
    "- **Sentiment Analysis**: Rule-based sentiment with negation handling\n",
    "- **Interlinear Glossing**: Linguistic annotation following Leipzig conventions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applications loaded successfully\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../src')\n",
    "\n",
    "from wolof_nlp.applications import (\n",
    "    tag,\n",
    "    extract_entities,\n",
    "    analyze_sentiment,\n",
    "    gloss\n",
    ")\n",
    "\n",
    "print(\"Applications loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. POS Tagging\n",
    "\n",
    "The POS tagger uses a combination of:\n",
    "- Lexicon lookup for known words\n",
    "- Morphological patterns (e.g., `-kat` suffix → agent noun)\n",
    "- Contextual rules (e.g., word after TAM marker → verb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Xale bi dafa lekk\n",
      "  Xale/NOUN  bi/DET  dafa/TAM  lekk/VERB\n",
      "\n",
      "Goor gi dem na Touba\n",
      "  Goor/UNK  gi/DET  dem/VERB  na/TAM  Tuba/NOUN\n",
      "\n",
      "Bindkat bi rafet na\n",
      "  Bindkat/NOUN.AGENT  bi/DET  rafet/ADJ  na/TAM\n"
     ]
    }
   ],
   "source": [
    "sentences = [\n",
    "    \"Xale bi dafa lekk\",\n",
    "    \"Goor gi dem na Touba\",\n",
    "    \"Bindkat bi rafet na\",\n",
    "]\n",
    "\n",
    "for sent in sentences:\n",
    "    tagged = tag(sent)\n",
    "    print(f\"\\n{sent}\")\n",
    "    print(\"  \" + \"  \".join(f\"{word}/{pos}\" for word, pos in tagged))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POS Tag Inventory\n",
    "\n",
    "| Tag | Description | Example |\n",
    "|-----|-------------|----------|\n",
    "| NOUN | Common noun | xale (child) |\n",
    "| VERB | Verb | dem (go), lekk (eat) |\n",
    "| TAM | Tense-Aspect-Mood marker | dafa, na, dina |\n",
    "| DET | Determiner | bi, gi, mi |\n",
    "| ADJ | Adjective | baax (good), rafet (beautiful) |\n",
    "| FWORD | French word | très, mais |\n",
    "| NOUN.AGENT | Agent noun (-kat) | bindkat (writer) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Named Entity Recognition\n",
    "\n",
    "NER identifies:\n",
    "- **PER**: Person names (Senegalese first/last names, religious titles)\n",
    "- **LOC**: Locations (Senegalese cities, regions, countries)\n",
    "- **ORG**: Organizations (media, religious groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dama bëgg Serigne Touba\n",
      "  Serigne Touba        PER   (confidence: 0.98)\n",
      "\n",
      "Fatou ak Mamadou dem nañu Dakar\n",
      "  Fatu                 PER   (confidence: 0.88)\n",
      "  Mamadu               PER   (confidence: 0.88)\n",
      "  Dakar                LOC   (confidence: 0.95)\n",
      "\n",
      "Soxna Astou mongi RTS\n",
      "  Soxna                PER   (confidence: 0.88)\n",
      "  Astu                 PER   (confidence: 0.55)\n",
      "  RTS                  ORG   (confidence: 0.92)\n"
     ]
    }
   ],
   "source": [
    "texts = [\n",
    "    \"Dama bëgg Serigne Touba\",\n",
    "    \"Fatou ak Mamadou dem nañu Dakar\",\n",
    "    \"Soxna Astou mongi RTS\",\n",
    "]\n",
    "\n",
    "for text in texts:\n",
    "    entities = extract_entities(text)\n",
    "    print(f\"\\n{text}\")\n",
    "    if entities:\n",
    "        for ent in entities:\n",
    "            print(f\"  {ent.text:<20} {ent.label:<5} (confidence: {ent.confidence:.2f})\")\n",
    "    else:\n",
    "        print(\"  No entities found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Sentiment Analysis\n",
    "\n",
    "The sentiment analyzer handles:\n",
    "- Wolof sentiment words (neex, baax, metti, bon...)\n",
    "- Morphological negation (-ul suffix)\n",
    "- Intensifiers (lool, torop)\n",
    "- French sentiment words in code-switched text\n",
    "- Discourse markers (waaye = \"but\" can flip sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text                                Sentiment    Score    Details\n",
      "--------------------------------------------------------------------------------\n",
      "Dafa neex lool                      POSITIVE     0.94     +['neex'] intensified\n",
      "Neexul                              NEGATIVE     0.91     -['neexul'] negated:['neexul']\n",
      "Baaxul waaye dafa rafet             POSITIVE     0.91     +['rafet'] negated:['baaxul']\n",
      "Dafa metti torop                    NEGATIVE     0.94     -['metti'] intensified\n",
      "Alhamdulillah, aksinaa              POSITIVE     0.91     +['alhamdulillah']\n"
     ]
    }
   ],
   "source": [
    "texts = [\n",
    "    \"Dafa neex lool\",\n",
    "    \"Neexul\",\n",
    "    \"Baaxul waaye dafa rafet\",\n",
    "    \"Dafa metti torop\",\n",
    "    \"Alhamdulillah, aksinaa\",\n",
    "]\n",
    "\n",
    "print(f\"{'Text':<35} {'Sentiment':<12} {'Score':<8} {'Details'}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for text in texts:\n",
    "    result = analyze_sentiment(text)\n",
    "    details = []\n",
    "    if result.positive_words:\n",
    "        details.append(f\"+{result.positive_words}\")\n",
    "    if result.negative_words:\n",
    "        details.append(f\"-{result.negative_words}\")\n",
    "    if result.negated_words:\n",
    "        details.append(f\"negated:{result.negated_words}\")\n",
    "    if result.intensified:\n",
    "        details.append(\"intensified\")\n",
    "    \n",
    "    print(f\"{text:<35} {result.sentiment.name:<12} {result.score:<8.2f} {' '.join(details)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Interlinear Glossing\n",
    "\n",
    "Produces linguistic annotation following Leipzig Glossing Rules:\n",
    "- Word segmentation into morphemes\n",
    "- Grammatical glosses (PFV, SBJF, NEG, etc.)\n",
    "- English translations from the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Xale bi dem na\n",
      "--------------------------------------------------\n",
      "Xale   bi   dem  na     \n",
      "xale   bi   dem  na     \n",
      "XALE   DET  DEM  3SG.PFV\n",
      "child  ?    go          \n",
      "\n",
      "Dafa naan ndox\n",
      "--------------------------------------------------\n",
      "Dafa      naan   ndox \n",
      "Dafa      naan   ndox \n",
      "3SG.VRBF  NAAN   NDOX \n",
      "          drink  water\n"
     ]
    }
   ],
   "source": [
    "sentences = [\n",
    "    \"Xale bi dem na\",\n",
    "    \"Dafa naan ndox\",\n",
    "]\n",
    "\n",
    "for sent in sentences:\n",
    "    result = gloss(sent)\n",
    "    print(f\"\\n{sent}\")\n",
    "    print(\"-\" * 50)\n",
    "    print(result.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wolof        Morphemes       Gloss           Translation\n",
      "-------------------------------------------------------\n",
      "Bindkat      bind-kat        BIND-NMLZ       write\n",
      "bi           bi              DET             ?\n",
      "wax          wax             WAX             speak/say\n",
      "na           na              3SG.PFV         \n"
     ]
    }
   ],
   "source": [
    "# Access individual glossed words\n",
    "result = gloss(\"Bindkat bi wax na\")\n",
    "\n",
    "print(f\"{'Wolof':<12} {'Morphemes':<15} {'Gloss':<15} {'Translation'}\")\n",
    "print(\"-\" * 55)\n",
    "for word in result.words:\n",
    "    print(f\"{word.wolof:<12} {word.morphemes:<15} {word.gloss:<15} {word.translation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Combined Pipeline Example\n",
    "\n",
    "Processing a comment with multiple analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Dafa sonnu lool, motax demul Kaolack\n",
      "\n",
      "POS Tags:\n",
      "  Dafa: TAM\n",
      "  sonnu: ADJ\n",
      "  lool: ADV\n",
      "  motax: CONJ\n",
      "  demul: VERB.NEG\n",
      "  Kaolack: PROPN.LOC\n",
      "\n",
      "Named Entities:\n",
      "  Kaolack: LOC\n",
      "\n",
      "Sentiment: NEGATIVE (score: 0.94)\n"
     ]
    }
   ],
   "source": [
    "text = \"Dafa sonnu lool, motax demul Kaolack\"\n",
    "\n",
    "print(f\"Text: {text}\\n\")\n",
    "\n",
    "# POS Tagging\n",
    "print(\"POS Tags:\")\n",
    "for word, pos in tag(text):\n",
    "    print(f\"  {word}: {pos}\")\n",
    "\n",
    "# NER\n",
    "print(\"\\nNamed Entities:\")\n",
    "for ent in extract_entities(text):\n",
    "    print(f\"  {ent.text}: {ent.label}\")\n",
    "\n",
    "# Sentiment\n",
    "result = analyze_sentiment(text)\n",
    "print(f\"\\nSentiment: {result.sentiment.name} (score: {result.score:.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation Notes\n",
    "\n",
    "All applications use **rule-based** approaches:\n",
    "\n",
    "- **POS Tagger**: Lexicon + morphological patterns + context rules\n",
    "- **NER**: Gazetteers (Senegalese names, places) + title patterns\n",
    "- **Sentiment**: Lexicon + negation morphology + discourse markers\n",
    "- **Glosser**: Morphological analyzer + dictionary lookup\n",
    "\n",
    "These are designed for Wolof-specific linguistic features and do not require training data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
